{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f680e2d-3abf-4452-afb8-e750d3c2e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Función para configurar y entrenar modelos con diferentes parámetros\n",
    "def entrenar_modelos(X_train, y_train):\n",
    "    # Configuraciones de parámetros\n",
    "    parametros_lr = {\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'max_iter': [100, 1000]\n",
    "    }\n",
    "    parametros_rf = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20]\n",
    "    }\n",
    "    parametros_gb = {\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'n_estimators': [100, 200]\n",
    "    }\n",
    "    \n",
    "    # Modelos\n",
    "    lr = LogisticRegression()\n",
    "    rf = RandomForestClassifier()\n",
    "    gb = GradientBoostingClassifier()\n",
    "    \n",
    "    # GridSearchCV para encontrar la mejor configuración de parámetros\n",
    "    grid_lr = GridSearchCV(lr, parametros_lr, cv=5, scoring='accuracy')\n",
    "    grid_rf = GridSearchCV(rf, parametros_rf, cv=5, scoring='accuracy')\n",
    "    grid_gb = GridSearchCV(gb, parametros_gb, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Entrenamiento\n",
    "    grid_lr.fit(X_train, y_train)\n",
    "    grid_rf.fit(X_train, y_train)\n",
    "    grid_gb.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_lr, grid_rf, grid_gb\n",
    "\n",
    "# Función para generar gráficos\n",
    "def generar_graficos(resultados, output_dir=\"graficos\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "    \n",
    "    # Accuracy\n",
    "    resultados.plot(x='Modelo', y='Accuracy', kind='bar', ax=axes[0], legend=False, title='Accuracy por Modelo')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    plt.savefig(f\"{output_dir}/accuracy.png\")\n",
    "    \n",
    "    # Precision\n",
    "    resultados.plot(x='Modelo', y='Precision', kind='bar', ax=axes[1], legend=False, title='Precision por Modelo')\n",
    "    axes[1].set_ylabel('Precision')\n",
    "    plt.savefig(f\"{output_dir}/precision.png\")\n",
    "    \n",
    "    # Recall\n",
    "    resultados.plot(x='Modelo', y='Recall', kind='bar', ax=axes[2], legend=False, title='Recall por Modelo')\n",
    "    axes[2].set_ylabel('Recall')\n",
    "    plt.savefig(f\"{output_dir}/recall.png\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/model_comparison.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Función para generar y guardar curvas ROC\n",
    "def generar_roc_curve(modelo, X_test, y_test, nombre_modelo, output_dir=\"graficos\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    y_pred_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {nombre_modelo}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f\"{output_dir}/roc_curve_{nombre_modelo}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    filename = \"partidas.csv\"\n",
    "    \n",
    "    # Datos limpios\n",
    "    df_limpio = pd.read_csv(filename)\n",
    "    \n",
    "    # Preprocesamiento de los datos\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    equipo0_encoded = mlb.fit_transform(df_limpio['equipo0'])\n",
    "    equipo1_encoded = mlb.transform(df_limpio['equipo1'])\n",
    "\n",
    "    X = pd.concat([pd.DataFrame(equipo0_encoded), pd.DataFrame(equipo1_encoded)], axis=1)\n",
    "    y_victoria = df_limpio['victoria']\n",
    "\n",
    "    # División del conjunto de datos\n",
    "    X_train_vic, X_test_vic, y_train_vic, y_test_vic = train_test_split(X, y_victoria, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Entrenamiento de modelos con diferentes configuraciones de parámetros\n",
    "    grid_lr, grid_rf, grid_gb = entrenar_modelos(X_train_vic, y_train_vic)\n",
    "\n",
    "    # Mejores modelos\n",
    "    best_lr = grid_lr.best_estimator_\n",
    "    best_rf = grid_rf.best_estimator_\n",
    "    best_gb = grid_gb.best_estimator_\n",
    "\n",
    "    # Predicciones y evaluación para victoria\n",
    "    y_pred_lr_vic = best_lr.predict(X_test_vic)\n",
    "    y_pred_rf_vic = best_rf.predict(X_test_vic)\n",
    "    y_pred_gb_vic = best_gb.predict(X_test_vic)\n",
    "\n",
    "    # Métricas para los mejores modelos\n",
    "    acc_lr_vic = accuracy_score(y_test_vic, y_pred_lr_vic)\n",
    "    acc_rf_vic = accuracy_score(y_test_vic, y_pred_rf_vic)\n",
    "    acc_gb_vic = accuracy_score(y_test_vic, y_pred_gb_vic)\n",
    "\n",
    "    # Métricas adicionales para victoria\n",
    "    precision_lr_vic = precision_score(y_test_vic, y_pred_lr_vic)\n",
    "    recall_lr_vic = recall_score(y_test_vic, y_pred_lr_vic)\n",
    "    f1_lr_vic = f1_score(y_test_vic, y_pred_lr_vic)\n",
    "    \n",
    "    precision_rf_vic = precision_score(y_test_vic, y_pred_rf_vic)\n",
    "    recall_rf_vic = recall_score(y_test_vic, y_pred_rf_vic)\n",
    "    f1_rf_vic = f1_score(y_test_vic, y_pred_rf_vic)\n",
    "\n",
    "    precision_gb_vic = precision_score(y_test_vic, y_pred_gb_vic)\n",
    "    recall_gb_vic = recall_score(y_test_vic, y_pred_gb_vic)\n",
    "    f1_gb_vic = f1_score(y_test_vic, y_pred_gb_vic)\n",
    "\n",
    "    # Validación cruzada para victoria\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    lr_cv_scores_vic = cross_val_score(best_lr, X, y_victoria, cv=skf, scoring='accuracy')\n",
    "    rf_cv_scores_vic = cross_val_score(best_rf, X, y_victoria, cv=skf, scoring='accuracy')\n",
    "    gb_cv_scores_vic = cross_val_score(best_gb, X, y_victoria, cv=skf, scoring='accuracy')\n",
    "\n",
    "    # Crear DataFrame con los resultados\n",
    "    resultados = pd.DataFrame({\n",
    "        'Modelo': ['Logistic Regression', 'Random Forest', 'Gradient Boosting'],\n",
    "        'Accuracy': [acc_lr_vic, acc_rf_vic, acc_gb_vic],\n",
    "        'Precision': [precision_lr_vic, precision_rf_vic, precision_gb_vic],\n",
    "        'Recall': [recall_lr_vic, recall_rf_vic, recall_gb_vic],\n",
    "        'F1-Score': [f1_lr_vic, f1_rf_vic, f1_gb_vic],\n",
    "        'Cross-Validated Accuracy': [lr_cv_scores_vic.mean(), rf_cv_scores_vic.mean(), gb_cv_scores_vic.mean()]\n",
    "    })\n",
    "\n",
    "    # Mostrar los resultados\n",
    "    print(resultados)\n",
    "\n",
    "    # Generar gráficos de métricas\n",
    "    generar_graficos(resultados)\n",
    "\n",
    "    # Generar curvas ROC\n",
    "    generar_roc_curve(best_lr, X_test_vic, y_test_vic, \"Logistic_Regression\")\n",
    "    generar_roc_curve(best_rf, X_test_vic, y_test_vic, \"Random_Forest\")\n",
    "    generar_roc_curve(best_gb, X_test_vic, y_test_vic, \"Gradient_Boosting\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
