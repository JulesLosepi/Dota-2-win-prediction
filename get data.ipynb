{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"partidas-1.csv\"\n",
    "equipo1 = []\n",
    "equipo0 = []\n",
    "matchID = []\n",
    "duration = []\n",
    "partidas=[]\n",
    "victoria = []\n",
    "\n",
    "def limpiar_datos(dartaframe):\n",
    "    df = dartaframe\n",
    "    df['equipo0'] = df['equipo0'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "    df['equipo1'] = df['equipo1'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "    df_limpio = df[(df['equipo0'].apply(len) == 5) & (df['equipo1'].apply(len) == 5)]\n",
    "    return df_limpio\n",
    "\n",
    "def get_public_matches():\n",
    "    url = \"https://api.opendota.com/api/publicMatches\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "def get_match_details(match_id):\n",
    "    url = f\"https://api.opendota.com/api/matches/{match_id}\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "def analizar_heroes(json_data):\n",
    "    for partida in json_data:\n",
    "        heroes_equipo0 = []\n",
    "        heroes_equipo1 = []\n",
    "        for item in partida:\n",
    "            if item.get('is_pick') and item.get('team') == 1:\n",
    "                heroes_equipo1.append(item.get('hero_id'))\n",
    "            elif item.get('is_pick') and item.get('team') == 0:\n",
    "                heroes_equipo0.append(item.get('hero_id'))\n",
    "        \n",
    "        equipo0.append(heroes_equipo0)\n",
    "        equipo1.append(heroes_equipo1)\n",
    "    \n",
    "    return equipo1, equipo0\n",
    "\n",
    "def extract_match_info(match_details):    \n",
    "    picks_bans = match_details.get('picks_bans', [])\n",
    "    duration = match_details.get('duration')\n",
    "    # informa 1 si la victoria es del equipo radiant, 0 si la victoria es del equipo dire\n",
    "    victoria = 1 if match_details.get('radiant_win') == True else 0\n",
    "    return duration, picks_bans, victoria\n",
    "    \n",
    "def unir_datos( equipo0, equipo1, victoria):\n",
    "    # Crear una lista de diccionarios con los datos\n",
    "    data = []\n",
    "    for i in range(len(matchID)):\n",
    "        data.append({\n",
    "            \"equipo0\": equipo0[i],\n",
    "            \"equipo1\": equipo1[i],\n",
    "            \"victoria\": victoria[i],\n",
    "        })\n",
    "    return data\n",
    "    \n",
    "\n",
    "    # Crear un DataFrame de pandas\n",
    "   # df = pd.DataFrame(data)\n",
    "\n",
    "    # Exportar a un archivo CSV\n",
    "    #df.to_csv( path, filename, index=False)\n",
    "# Funci√≥n principal\n",
    "def main():\n",
    "    public_matches = get_public_matches()\n",
    "\n",
    "    \n",
    "\n",
    "    for match in public_matches[:100]:  # Limitamos a las primeras 10 partidas para evitar demasiadas solicitudes\n",
    "        match_id = match['match_id']\n",
    "        match_details = get_match_details(match_id)\n",
    "        match_duration, picks_bans, winner = extract_match_info(match_details)\n",
    "        \n",
    "        heroes_equipo1, heroes_equipo0 = analizar_heroes([picks_bans])\n",
    "        matchID.append(match_id)\n",
    "        duration.append(match_duration)\n",
    "        victoria.append(winner)\n",
    "\n",
    "    data = unir_datos( equipo0, equipo1, victoria)\n",
    "\n",
    "    # Crear un DataFrame de pandas\n",
    "    print(data)\n",
    "    df = pd.DataFrame(data)\n",
    "    dataLimpio = limpiar_datos(df)\n",
    "    print(df)\n",
    "    dataLimpio.to_csv( filename, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ruta_archivos = 'C:/Users/Jules/'  # Reemplaza con la ruta correcta\n",
    "archivos_csv = [f for f in os.listdir(ruta_archivos) if f.endswith('.csv')]\n",
    "# Leer y concatenar los archivos CSV\n",
    "dataframes = []\n",
    "for archivo in archivos_csv:\n",
    "    df = pd.read_csv(os.path.join(ruta_archivos, archivo))\n",
    "    dataframes.append(df)\n",
    "\n",
    "df_concatenado = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df_concatenado\n",
    "\n",
    "df_concatenado.to_csv( \"datosconv.csv\", index=False)\n",
    "\n",
    "print(df_concatenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivos = 'C:/Users/Jules/'  # Reemplaza con la ruta correcta\n",
    "archivos_csv = [f for f in os.listdir(ruta_archivos) if f.endswith('.csv')]\n",
    "# Leer y concatenar los archivos CSV\n",
    "dataframes = []\n",
    "for archivo in archivos_csv:\n",
    "    df = pd.read_csv(os.path.join(ruta_archivos, archivo))\n",
    "    dataframes.append(df)\n",
    "\n",
    "df_concatenado = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df_concatenado\n",
    "\n",
    "df_concatenado.to_csv( \"datosconv3.csv\", index=False)\n",
    "\n",
    "print(df_concatenado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
